# This is SPL examples to implement anomalous network traffic behaviors using Network_Traffic data model.
# You can use below features other than sum(bytes) to detect anomalous network activities.
# - Session Count
# - Uniqueu Source IP

[Draw time chart to determine on/off hours in your traffic activties]
# Run below search for previous week to determine to see which hour of day is on-hours for your network traffic.
| tstats summariesonly=true sum(All_Traffic.bytes) from datamodel=Network_Traffic.All_Traffic by _time span=1h

[Draw histogram for each time category, 1. weekday on-hour, 2. weekday off-hour, 3. weekend on-hour, 4. weekend off-hour]
# This needs to run for enough time range. It's expected to run for last 30 days at least.
# You need to determine the condition to identify weekday, weekend, on-hour, and off-hour based on the your traffic bevior.
# The example below is the SPL to draw histogram for weekday on-hour. You need to change the search condition to draw histograms for the other categories.
# Adjust span parameter value for bin command to fit the number of bins for the better histogram shape.
| tstats summariesonly=true sum(All_Traffic.bytes) from datamodel=Network_Traffic.All_Traffic where earliest=-30d@d AND latest=@d by _time span=5m
| eval date = strftime(_time, "%Y/%m/%d") 
| eval dow = strftime(_time, "%a") 
| eval hod = strftime(_time, "%H") 
| eval moh = strftime(_time, "%M")
| eval tod = if(dow = "Sat" OR dow = "Sun", "weekend", "weekday")
| eval toh = if(hod >= 10 AND hod <=17, "on-hour", "off-hour")
| bin sum(All_Traffic.bytes) span=1000000
| search tod=weekday toh=on-hour
| stats count by sum(All_Traffic.bytes) 
| makecontinuous sum(All_Traffic.bytes)

[Draw histogram for specific IP at specific time, Fri, 8:00 am to 8:05 am]
# This needs to run for enough time range. It's expected to run for last 30 days at least.
source="client_bytes.csv.zip:*" host="client_bytes" earliest=01/01/2022:0:0:0 latest=01/01/2023:0:0:0 clientip=107.3.146.207
| tstats summariesonly=true count sum(All_Traffic.bytes) as bytes from datamodel=Network_Traffic.All_Traffic by _time All_Traffic.src_ip span=5m
| eval date = strftime(_time, "%Y/%m/%d") 
| eval dow = strftime(_time, "%a") 
| eval hod = strftime(_time, "%H") 
| eval moh = strftime(_time, "%M")
| eval pod = floor(hod / 8) * 8 
| search dow=Fri hod=8 moh=0
| bin bytes span=100
| stats count by bytes
| sort bytes
| makecontinuous

[Create stats model 5m]
# This needs to run for enough time range. It's expected to run for last 30 days at least.
source="client_bytes.csv.zip:*" host="client_bytes" earliest=01/01/2022:0:0:0 latest=01/01/2023:0:0:0
| bin _time span=5m
| stats count sum(bytes) as bytes by _time clientip
| eval date = strftime(_time, "%Y/%m/%d") 
| eval dow = strftime(_time, "%a") 
| eval hod = strftime(_time, "%H") 
| eval moh = strftime(_time, "%M")
| stats dc(date) as num_date_points_5m count as num_data_points_5m sum(count) as num_raw_points_5m avg(bytes) as avg_bytes_5m stdev(bytes) as stdev_bytes_5m p50(bytes) as p50_bytes_5m p75(bytes) as p75_bytes_5m p25(bytes) as p25_bytes_5m by clientip dow hod moh
| eval iqr_5m = p75_bytes_5m - p25_bytes_5m
| outputlookup bytes_stats_by_clientip_5m.csv
